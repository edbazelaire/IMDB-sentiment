{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_5uwhvTgeT_z"
   },
   "source": [
    "# Analyse de setiments sur le dataset IMDB\n",
    "\n",
    "**Objectif** Finetuner un LLM afin qu'il puisse déterminer si un commentaire, fait par un utilisateur à propos d'un film, est positif ou négatif.<br>\n",
    "Comparer sa précision avec un modèle \"baseline\" classique."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cIoMeM3ufbyw"
   },
   "source": [
    "## Partie 1 - Analyse et Interprétation des données\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7RaaaKvWlen5"
   },
   "source": [
    "### 1.1 Vérification des données\n",
    "Dans un premier temps, vérifions que nos données sont correctes : en avons nous suffisement ? Sont elles bien réparties ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "83a05c745b05432fab300a01ed27136f",
      "60065c8ce25f438a9bd589300b90a59a",
      "82452d23492b4912ae2117260f1fbed1",
      "d4b05e0deb6d47bda844fe4bbdc5f966",
      "083514508ec54c5caa1f672895b1515f",
      "623a9a86ddb044aa97ce66ddab58e091",
      "6078c271b3bb4d25af997e70d08c7a43",
      "9f374f357a2b4843a56a8f1ff00752e8",
      "5fe9f075d8aa45b7b4f79a7db7834b0b",
      "5d2749c015a6421b93b0be63510e9564",
      "3d73499003ed49279504eca5b073ee29",
      "bbbe9eb82a6d4f349898b38a84022d1b",
      "13306259e439402f8975e70aaebc27a8",
      "dddd2e9dbaf348d788d3d10709af86d4",
      "8f88345ee9ad41409a7d90661ed2fcbd",
      "703547978c85449486388fb92a0f8ddc",
      "8b86c84519d3464ca5999f183828c29b",
      "b4c06122e3404236a1e0a59ab5d70b23",
      "7b28ba000efd470da5020d6fa82bcca4",
      "88479b3c3ccd4c8882cc47e0c333ff6d",
      "3074b1b9ec31490487804c76855f1a8e",
      "fb2d6dddd51d4414b2635277156b13a6",
      "8045c532c2ab446db573d1184593bd2a",
      "e813035b68844a45821da5f729d8a835",
      "94aba21c65dd42bdb00a0686b0abfbcd",
      "a06c6c6ac43d44918c5715c877465a91",
      "af6d97cb901445d6b393c706404d3d2a",
      "cb5325d558eb403685f1f3df7c329925",
      "e4d7ce7446d442e1a4f752d62746f5ba",
      "c70c0657ce3443619e092ed581648d83",
      "11422122a2f04ba889d1fb31898c79f4",
      "4cb039d247da49b391cf0673b4a01417",
      "e1a9f16b6e3646f5bd9597301188cceb",
      "fa30c7ca193b42fba0219f9e65e89e4f",
      "013efec7fc014b33af78d611b3d0d531",
      "b1acf13b7add4dccbb6599b88bc919e8",
      "701ffa757af948c3b744c900a164b9ec",
      "e467cb47e59844d89a3c3e0248381b21",
      "cb2ce89238404fa09ca7adfd09db2339",
      "e7d2dd877a1a4658aecad7e5b1235d1e",
      "fd14f2a4e2474b81a0a2491f0769f746",
      "9e3c40f9136e4f9883779a3a4f0a92cb",
      "275c8802064c41d7baca676f87e1d505",
      "3cf9baa6777245ce9deb602506bb46ce",
      "ed27f9ab3a854a38a0c703be32b632c7",
      "adc82a4626b4436aae74fb7d9e3fda15",
      "2643616bf9a340a9b4d4d36780dd8662",
      "05dbfce2be614e749e47d3e8c19445fc",
      "eba85e9a01574bd3ad5d37c46a79fe64",
      "6f8cbce440914ced91cf274e26f74419",
      "54135bd0382647caa04995a6d2770978",
      "37178b5873794a9f8d52795263521c22",
      "a158c8fbef3c4823aa3cc88e433afab1",
      "c9b5c16124494daaa4bd1ea158098cf2",
      "c78b169a8b8f41dc95c69655b74985b0",
      "8de1af0d57b14d3ea9d0537c9c662e73",
      "043a8752215c4b198e0f5f8ee4d902f4",
      "95d402885be64d9286a94d357d61588f",
      "e5dbbf7795494113a85a3d6045439a10",
      "19f04d5587b64927b502665d69941d5e",
      "2973a955a3c24f58988b7af70bdda882",
      "9c5ac203800c4418a7aac012b71746ff",
      "4e08f50e976d4511b8a7692cecdccfb6",
      "1e7e2a6ff43c450696cde6fef2f3906b",
      "938d79849e5d42f69a0b4541d9722752",
      "c565855777b141959af9f5355666a3eb",
      "04d8687d799f486f96aa1276b8eadb7c",
      "64c1b0a62bb046f099f1aa7f18791528",
      "aeb05786d7654c6483d4eded7d79a8ed",
      "8caae8a3412c4609b34269ad7f067519",
      "bcd3c61238e1494e8f651c84a3b82edf",
      "80d4720c4b984b6b8250ad01c5726013",
      "c889e35200d045109102048435ea7daa",
      "5d3476131b3c48628e5e40f091787083",
      "0e94bb3fe5d4429ea0b17df7bfc02a46",
      "a85c1f84a7144063a30313f7f82b80bd",
      "6ade99b266c34744a124a211732cee05"
     ]
    },
    "id": "rePZ1M_XXxeH",
    "outputId": "6c5f7914-9ca0-4046-ee22-7e4fa3a1b40a"
   },
   "outputs": [],
   "source": [
    "!pip install datasets matplotlib wordcloud\n",
    "!pip install emoji\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "import emoji\n",
    "\n",
    "from datasets import load_dataset\n",
    "\n",
    "# load dataset\n",
    "dataset = load_dataset(\"imdb\")\n",
    "\n",
    "# set as DataFrames\n",
    "df_train = pd.DataFrame(dataset['train'])\n",
    "df_test = pd.DataFrame(dataset['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m31vkcA6hNkf"
   },
   "source": [
    "#### Vérification des doublons et valeurs manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "p-F6BdnOhImf",
    "outputId": "f1a5c127-3886-48bd-c5b4-834ae748d3b7"
   },
   "outputs": [],
   "source": [
    "print(\"Missing values (train):\\n\", df_train.isna().sum())\n",
    "print(\"Missing values (test):\\n\", df_test.isna().sum())\n",
    "\n",
    "print(\"Duplicated rows in train:\", df_train.duplicated(subset=\"text\").sum())\n",
    "print(\"Duplicated rows in test:\", df_test.duplicated(subset=\"text\").sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aBivWtHphVU0"
   },
   "source": [
    "Aucune valeur manquantes. On voit en revanche des valeurs doublées, regardons si ces doublons donnent le même label (par exemple, une personne pourrait dire \"this actor is insane\" positivement et une autre négativement).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IIkJX-xfPKIS",
    "outputId": "326b552a-ef33-4f08-9d90-8ca6711ccf8a"
   },
   "outputs": [],
   "source": [
    "dup_texts = df_train[df_train.duplicated(subset=\"text\", keep=False)]\n",
    "dup_groups = dup_texts.groupby(\"text\")[\"label\"].agg(list).reset_index()\n",
    "conflicts = dup_groups[dup_groups[\"label\"].apply(lambda x: len(set(x)) > 1)]\n",
    "\n",
    "print(f\"Inconsistent duplicates (same text but different labels): {len(conflicts)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "T8Xk8TtcPsKY"
   },
   "source": [
    "On voit que les texts dupliqués ont le même label. On peut donc retirer les doublons de notre dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "65Zz2DhoQmGv",
    "outputId": "bae6ccb2-7548-4e27-d579-910f44620f51"
   },
   "outputs": [],
   "source": [
    "# Remove duplicates in train\n",
    "before_train = len(df_train)\n",
    "df_train_clean = df_train.drop_duplicates(subset=\"text\", keep=\"first\").reset_index(drop=True)\n",
    "after_train = len(df_train_clean)\n",
    "\n",
    "print(f\"Train set: {before_train} → {after_train} (removed {before_train - after_train} duplicates)\")\n",
    "\n",
    "# Remove duplicates in test\n",
    "before_test = len(df_test)\n",
    "df_test_clean = df_test.drop_duplicates(subset=\"text\", keep=\"first\").reset_index(drop=True)\n",
    "after_test = len(df_test_clean)\n",
    "\n",
    "print(f\"Test set: {before_test} → {after_test} (removed {before_test - after_test} duplicates)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2dW2-wX4lM1o"
   },
   "source": [
    "#### Vérification des Labels\n",
    "Vérifions que nos labels sont bien répartis équitablement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "gaKrY7NKX-Pj",
    "outputId": "70c427bc-f6b8-4228-dc94-731ab14549ff"
   },
   "outputs": [],
   "source": [
    "# Count labels in train/test\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "\n",
    "sns.countplot(x=\"label\", data=df_train, ax=axes[0], hue=\"label\", palette=\"Set1\")\n",
    "axes[0].set_title(\"Train set label distribution\")\n",
    "axes[0].set_xticks([0, 1])\n",
    "axes[0].set_xticklabels([\"Negative\", \"Positive\"])\n",
    "\n",
    "sns.countplot(x=\"label\", data=df_test, ax=axes[1], hue=\"label\", palette=\"Set1\")\n",
    "axes[1].set_title(\"Test set label distribution\")\n",
    "axes[1].set_xticks([0, 1])\n",
    "axes[1].set_xticklabels([\"Negative\", \"Positive\"])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "print(\"Train label distribution:\\n\", df_train['label'].value_counts(normalize=True))\n",
    "print(\"Test label distribution:\\n\", df_test['label'].value_counts(normalize=True))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZPCaoUXOjbVf"
   },
   "source": [
    "En ce qui concere les labels tout va bien, les données sont bien réparties.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D32OVtqcljyN"
   },
   "source": [
    "#### Examples de review\n",
    "Regardons à quoi ressemble nos données d'entré"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "idrJs_6JhxMe",
    "outputId": "0b9ae63c-566f-43a0-c22f-551241305028"
   },
   "outputs": [],
   "source": [
    "print(\"Example positive review:\\n\")\n",
    "print(df_train[df_train['label']==1]['text'].iloc[:5][:500])\n",
    "\n",
    "print(\"\\nExample negative review:\\n\")\n",
    "print(df_train[df_train['label']==0]['text'].iloc[:5][:500])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WsYWA9uCiEQj"
   },
   "source": [
    "Les données sont bien des \"raw\" commentaires d'utilisateurs. On comprend donc que l'on aura probablement à faire à des fautes d'orthographe, de synthaxe, des emojis, ...\n",
    "Faisons une petite analyse de nos données pour voir si l'on retrouve ce genre de choses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yEC3ukwXi0Ye",
    "outputId": "8b12120d-4b14-4e8d-f09a-f110285bbc7b"
   },
   "outputs": [],
   "source": [
    "def detect_strange_text(text):\n",
    "    \"\"\"\n",
    "    Detects if a text contains emojis, strange characters or abnormal tokens.\n",
    "    Returns a dict with flags.\n",
    "    \"\"\"\n",
    "    result = {\n",
    "        \"has_emoji\": bool(emoji.emoji_list(text)),\n",
    "        \"has_non_ascii\": bool(re.search(r\"[^\\x00-\\x7F]\", text)),  # non standard ASCII\n",
    "        \"has_repeated_letters\": bool(re.search(r\"(.)\\1{4,}\", text)),  # e.g. 'sooooo'\n",
    "    }\n",
    "    return result\n",
    "\n",
    "# Apply to dataset (train sample)\n",
    "sample_check = df_train['text'].sample(10, random_state=42).apply(detect_strange_text)\n",
    "print(sample_check)\n",
    "\n",
    "# Percentage of reviews with anomalies\n",
    "flags = df_train['text'].apply(lambda x: detect_strange_text(x))\n",
    "\n",
    "flags_df = pd.DataFrame(flags.tolist())\n",
    "print(flags_df.mean())  # proportion of True values per category"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sAph1ynKjsi2"
   },
   "source": [
    "On peut voir que l'on a effectivement des caractères spéciaux et des emojis dans nos commentaires. Cela représente cela dit un faible pourcentage de nos données."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QwWLYKQ0lR7d"
   },
   "source": [
    "#### Longueur des commentaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "H_nWXb-hhApY",
    "outputId": "04924c72-5ce6-43b9-91e0-af9074faaa5f"
   },
   "outputs": [],
   "source": [
    "df_train[\"text_length\"] = df_train[\"text\"].apply(lambda x: len(x.split()))\n",
    "df_test[\"text_length\"] = df_test[\"text\"].apply(lambda x: len(x.split()))\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12,5))\n",
    "sns.histplot(df_train[\"text_length\"], bins=50, ax=axes[0], color=\"blue\")\n",
    "axes[0].set_title(\"Train reviews length distribution\")\n",
    "sns.histplot(df_test[\"text_length\"], bins=50, ax=axes[1], color=\"orange\")\n",
    "axes[1].set_title(\"Test reviews length distribution\")\n",
    "plt.show()\n",
    "\n",
    "print(df_train[\"text_length\"].describe(percentiles=[.25, .5, .75, .9, .95]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HIX9HpMlYMcj"
   },
   "source": [
    "### 1.2 Représentation des mots\n",
    "Quels sont les mots les plus utilisés dans un commentaire négatif ou positif ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HcakFkjpaBXW"
   },
   "source": [
    "#### Top 20 des mots les plus utilisés\n",
    "Regardons pour chaque label quels sont les mots les plus récurrents\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bh1OqTzGY2kG",
    "outputId": "75145d77-82c5-4f97-ab95-5960aaa0ab89"
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import re\n",
    "\n",
    "def tokenize(text):\n",
    "    return re.findall(r\"\\b\\w+\\b\", text.lower())\n",
    "\n",
    "# count positives / negatives\n",
    "pos_words = Counter([w for text in df_train[df_train['label']==1]['text'] for w in tokenize(text)])\n",
    "neg_words = Counter([w for text in df_train[df_train['label']==0]['text'] for w in tokenize(text)])\n",
    "\n",
    "print(\"Top 20 mots positifs:\", pos_words.most_common(20))\n",
    "print(\"Top 20 mots négatifs:\", neg_words.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "egcCOxq6R2zN"
   },
   "source": [
    "#### Filtrer les mots neutres\n",
    "Comme nous pouvons le constater, les mots les plus utilisés sont des mots neutres : \"the\", \"and\", \"a\", ...\n",
    "Afin d'avoir une meilleur représentation, enlevons les mots qui sont preque autant présents dans les deux catégories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "M4jigKpja7zQ",
    "outputId": "8456acb5-4ca4-4ec1-bfe4-592f9126de86"
   },
   "outputs": [],
   "source": [
    "def remove_weakly_discriminant(pos_counter, neg_counter, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Remove words that are too common in both classes.\n",
    "    A word is removed if its count in one class is >= threshold * count in the other class.\n",
    "    \"\"\"\n",
    "    pos_filtered = Counter()\n",
    "    neg_filtered = Counter()\n",
    "\n",
    "    # Process positive words\n",
    "    for w, c in pos_counter.items():\n",
    "        other_count = neg_counter.get(w, 0)\n",
    "        if other_count < threshold * c:  # keep only if relatively discriminant\n",
    "            pos_filtered[w] = c\n",
    "\n",
    "    # Process negative words\n",
    "    for w, c in neg_counter.items():\n",
    "        other_count = pos_counter.get(w, 0)\n",
    "        if other_count < threshold * c:\n",
    "            neg_filtered[w] = c\n",
    "\n",
    "    return pos_filtered, neg_filtered\n",
    "\n",
    "\n",
    "# Example usage\n",
    "pos_clean, neg_clean = remove_weakly_discriminant(pos_words, neg_words, threshold=0.5)\n",
    "\n",
    "print(\"Top discriminant positive words:\", pos_clean.most_common(20))\n",
    "print(\"Top discriminant negative words:\", neg_clean.most_common(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HCL9r6p9dKsI"
   },
   "source": [
    "Les mots ressortits semblent parfaitement cohérents. Affichons les afin d'en avoir une meilleur représentation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E4n6YyDIR_nP"
   },
   "source": [
    "#### Nuage de mots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "7IZ-_lABYK89",
    "outputId": "dd93dedb-86a7-463c-aa46-678bf9623077"
   },
   "outputs": [],
   "source": [
    "from wordcloud import WordCloud\n",
    "\n",
    "# Reconstruct text from filtered discriminant words\n",
    "pos_text_filtered = \" \".join([w for w, c in pos_clean.items() for _ in range(c)])\n",
    "neg_text_filtered = \" \".join([w for w, c in neg_clean.items() for _ in range(c)])\n",
    "\n",
    "# -- WordCloud negative (discriminant)\n",
    "wordcloud_neg = WordCloud(width=800, height=400, background_color=\"white\", colormap='Reds').generate_from_frequencies(neg_clean)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud_neg, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Discriminant Words - Negative\")\n",
    "plt.show()\n",
    "\n",
    "# -- WordCloud positive (discriminant)\n",
    "wordcloud_pos = WordCloud(width=800, height=400, background_color=\"white\", colormap='Greens').generate_from_frequencies(pos_clean)\n",
    "plt.figure(figsize=(10,5))\n",
    "plt.imshow(wordcloud_pos, interpolation=\"bilinear\")\n",
    "plt.axis(\"off\")\n",
    "plt.title(\"Discriminant Words - Positive\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "q4p2yi7uSCKv"
   },
   "source": [
    "#### Plot bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "GimGxyhbYiCP",
    "outputId": "73887947-9681-45d6-9984-e834b492d6c9"
   },
   "outputs": [],
   "source": [
    "def plot_top_words(counter, label, n=20, color=\"green\"):\n",
    "    # Get the top-N most frequent words\n",
    "    top_words = counter.most_common(n)\n",
    "    words, counts = zip(*top_words)\n",
    "\n",
    "    plt.figure(figsize=(10,6))\n",
    "    plt.barh(words[::-1], counts[::-1], color=color)\n",
    "    plt.xlabel(\"Frequency\")\n",
    "    plt.title(f\"Top {n} discriminant words - {label}\")\n",
    "    plt.show()\n",
    "\n",
    "# Plot Top 20 for negative words\n",
    "plot_top_words(neg_clean, \"Negative\", n=20, color=\"red\")\n",
    "\n",
    "# Plot Top 20 for positive words\n",
    "plot_top_words(pos_clean, \"Positive\", n=20, color=\"green\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMHQ2aeIL8rG"
   },
   "source": [
    "### Conclusions\n",
    "Le jeu de donné est bien fournit (50 000 data) et propre (données variées, bien représentatives, bien réparties). Il ne semble pas nécessaire d'aller chercher d'autres jeux de données pour le compléter.\n",
    "Les IA devraient facilement réeussir à effectuer une analyse de sentiments."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P_YOVKhRTN-7"
   },
   "source": [
    "## Partie 2 Baseline Model (TF-IDF + LogReg)\n",
    "En modèle de base, prennons une pipeline simple, rapide et efficace :\n",
    "\n",
    "*   Vectorisation TF-IDF des reviews (transformer les textes en vecteurs pondérés).\n",
    "\n",
    "*   Logistic Regression comme classificateur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ikT8DycPet-W",
    "outputId": "e1caf660-8ef9-439b-bdae-b954f4a5a185"
   },
   "outputs": [],
   "source": [
    "# Install scikit-learn if needed\n",
    "!pip install scikit-learn -q\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Use the clean datasets (no duplicates)\n",
    "X_train = df_train_clean[\"text\"].values\n",
    "y_train = df_train_clean[\"label\"].values\n",
    "\n",
    "X_test = df_test_clean[\"text\"].values\n",
    "y_test = df_test_clean[\"label\"].values\n",
    "\n",
    "# Define pipeline: TF-IDF + Logistic Regression\n",
    "baseline_model = Pipeline([\n",
    "    (\"tfidf\", TfidfVectorizer(max_features=50000, ngram_range=(1,2))),\n",
    "    (\"clf\", LogisticRegression(max_iter=200, solver=\"saga\"))\n",
    "])\n",
    "\n",
    "# Train\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred = baseline_model.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"Baseline TF-IDF + Logistic Regression\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred, target_names=[\"Negative\", \"Positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qGbwQDnAghIE"
   },
   "source": [
    "Explications des paramètres :\n",
    "\n",
    "**TfidfVectorizer**\n",
    "  - max_features=50000 : limite le vocabulaire (évite explosion mémoire).\n",
    "\n",
    "  - ngram_range=(1,2) : prend en compte mots seuls + bigrammes (ex. \"very good\", \"not bad\").\n",
    "\n",
    "**LogisticRegression**\n",
    "\n",
    "  - solver = \"saga\" gère bien les grands datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lVffxCjiawQI"
   },
   "source": [
    "## Partie 3 Modèles finetuné"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WaRiNZA6iEO5"
   },
   "source": [
    "### Modèles candidats pour le fine-tuning\n",
    "1. **BERT-base**\n",
    "\n",
    "  - Type : Transformer bidirectionnel.\n",
    "  - Taille : 110M paramètres.\n",
    "  - Avantages : Standard très robuste pour classification de texte.\n",
    "  - Inconvénients : Modèle un peu ancien, parfois dépassé par des modèles plus récents.\n",
    "\n",
    "2. **DistilBERT** *(selectionné)*\n",
    "\n",
    "  - Type : Version compressée de BERT (40% plus petit, 60% plus rapide).\n",
    "  - Taille : 66M paramètres.\n",
    "  - Avantages : Plus rapide et moins coûteux en ressources GPU - parfait pour Google Colab.\n",
    "  - Inconvénients : Légère baisse de performance (~1-2% de moins que BERT-base).\n",
    "\n",
    "3. **RoBERTa-base**\n",
    "\n",
    "  - Type : BERT retravaillé avec plus de données et un entraînement plus long.\n",
    "  - Taille : 125M paramètres.\n",
    "  - Avantages : Plus performant que BERT sur la plupart des benchmarks NLP.\n",
    "  - Inconvénients : Plus lourd, plus lent que DistilBERT.\n",
    "\n",
    "\n",
    "J'ai donc choisit DistilBERT, je trouve que c’est un compromis excellent entre performance et efficacité (surtout sur GPU Colab qui a une mémoire limitée).\n",
    "Fine-tuning rapide, et il est supporté directement par Hugging Face."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JujYqrHqV0qG"
   },
   "source": [
    "### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0mPJLCZBTSix",
    "outputId": "cf2b82f3-7e0f-4b7a-d402-7ba4122381e7"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate accelerate -q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Sta3NV-zWg3c"
   },
   "source": [
    "### 3.1 Prétraitement (tokenisation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241,
     "referenced_widgets": [
      "3af8f2ebd58344c38bbcacc167559fc3",
      "b48c00509bc145599d19b0706808f195",
      "659e32627a2c475cb49175e465cb1298",
      "a5e082b509de43d4a60d8bbc3b5722e6",
      "9c25e6ab442543a7989804742512accb",
      "f4c3c72243df4bbd9232558877854221",
      "08f86e1e711c407b8144e884fad8a771",
      "244dae971bd74a9d890af6bb07ca15cd",
      "6a69fcc252f841e09f48020ce718d182",
      "899edb6b82ad4b36999aeab705576ed2",
      "6f0e7bc198e844b6a4efdd70e216982b",
      "f448ed8bc624405bb11b0e3216898170",
      "97c0a213d4aa4807836bcc901a9a95ae",
      "6ad31e96d3ba4509aee4a8f79814ab48",
      "9e98585b1f2f414d96043eb4e8400546",
      "d0b9f160a75047f2b408cbd5a2eca08e",
      "14a19fe7e26940cd8a475b9a6ee504c0",
      "39cb752683594b7785e935a17130394b",
      "1b4cf3372f374e798038c88114cd010e",
      "2bd4cb3cc7934719b62f35ef9c649ad1",
      "421dd5557a9a48fa99b5eeef902b7aad",
      "b6fe8dd0b16e462ea0612413fa44e1c3",
      "da528fefeba5413e8efe6e6fdd5eca56",
      "2dfc26f178be4ccd96504ae496852d5b",
      "4b07af00a6f841d8b125bd10ef794e4f",
      "da4f81ea34e346a78d7b372ab08ae467",
      "54a4aca19da840769098173443b56912",
      "d52d8df7467c45f0a9a4388ab89203c7",
      "5b9b87e8fc5543b3b6b1a43b8e022bab",
      "d5dc311e6ab64c4cbd7ea2a6fb43bec8",
      "8c5b0c34d0dd4284aacb1329a919c964",
      "479d5f3625034ca49afcc4a4f547c338",
      "0dd44588792d46709fe8f8e4cc44bf73",
      "1b03f76bb99f4a1a86412297b7365017",
      "09224444711349d8af9fa54321e258f5",
      "d7149dfe2bc84d73b639d3dac4514e38",
      "844e52d51a5c409fb082682c2d4590ff",
      "2539f7444725420b8bdcb43e5ccf1a6c",
      "a52bd2db954747cba2bf211a980ab851",
      "536f2c080df245298de601e5ee26f6e7",
      "eeba6386ce404a5d877199bef698ed30",
      "729033acc8324f59a4815838b836015d",
      "5631b0af3ebe4efea735d18e7ac2ffe7",
      "2040483d648c4326b43b3be121ebcc14",
      "eb1e3f9b62a646e8b1b55a598be74c24",
      "76c8116c588b41fc8fcfdec73d112a99",
      "4ba9677db3c4406b9cf74430a7ec84da",
      "8745aa6b4c0a4b3d886ca0361ca3a50e",
      "c2edccb0551b4e08ab15d75469626bfc",
      "00b7409f50534c7dad77df6a87ef2e50",
      "602db78b62a94cb1ad4a6b718ba9f326",
      "bfd06dc9e50043d7901ac0a7ca71314a",
      "33435bd0e1f648fab4ee45b2d268bdfa",
      "254495f768194d0dba8cc84ab784946b",
      "145e97982ef04521a21b35167611c1da",
      "bad8807afbe74916b05546c51bbefc88",
      "5f7d4f67da914be5aed53f51e4ee1fa9",
      "fc6af5cdfea149118b7e88554e399b65",
      "3e152ceb3f5c4be7870ba5a30b8acb8e",
      "154785c40f4c46a8932d33a02184d857",
      "a9d1a7695ce641db85728317d2f38993",
      "b0ee1c84f7504cd399790f3a957aad64",
      "fe0e939ececd480e87f2563947ae4e98",
      "46cf42ff1920489eabcda819869d89a6",
      "25816e8d227644e2807652213ea6bda5",
      "42f00384409345ce9318de2c23a57fa2",
      "940934b9d8f44f26bfcb2e6f1d696762",
      "b80a94086a5b412fb0d9b2840db5f995",
      "1be9037bfd14403a8a475998c84cf88e",
      "726793e2122e4082af0ab851d24f09e1",
      "4bc3219419974f25a8096fb75b9ef567",
      "753dc1d0acb94393bf67e3dcb67b6c88",
      "84a31be8b9a04e33aee9fe42dd9b8283",
      "12d459f00139474da5fd25ba07200f82",
      "07c6497d116642638b6d630579a13b34",
      "655ee2af847444cfa860b4d0c57f3efd",
      "8c3ed4997ef14ca583762db0b1b8e350"
     ]
    },
    "id": "X5V_2yFWVzsx",
    "outputId": "2cff40b4-d989-4699-874c-37af9ec3d0af"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertTokenizerFast\n",
    "\n",
    "# Load DistilBERT tokenizer\n",
    "tokenizer = DistilBertTokenizerFast.from_pretrained(\"distilbert-base-uncased\")\n",
    "\n",
    "# Tokenize function\n",
    "def tokenize_fn(batch):\n",
    "    return tokenizer(batch[\"text\"], padding=\"max_length\", truncation=True, max_length=256)\n",
    "\n",
    "# Apply tokenization\n",
    "tokenized_dataset = dataset.map(tokenize_fn, batched=True)\n",
    "\n",
    "# Keep only necessary columns\n",
    "tokenized_dataset = tokenized_dataset.remove_columns([\"text\"])\n",
    "tokenized_dataset.set_format(\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "pBySlFMwW81o"
   },
   "source": [
    "### 3.2 Préparation du modèle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 105,
     "referenced_widgets": [
      "d9e0769fdad541788e8f79605c36dc79",
      "b574719842224dd388ef7e2155694bbc",
      "36028c159add4a73ae123184471024a6",
      "ed99bf1077a24619bfa4e7ffdc860ef9",
      "f276aa69a71744e2989edd7bf2e68dda",
      "44ed0900675941eeb0b20d946dd2af02",
      "5b3202af87454a06b30eb083a2490bce",
      "be4654c6dc0545b6b83c89d1f2109c08",
      "694e4c7f4be24fecaeb1219e308b81ac",
      "c5a157c1b5994bd29154f7ce09c7ccb8",
      "3fb9056a66614c56bced276776d73f66"
     ]
    },
    "id": "MiYN3DkiWEkg",
    "outputId": "e0039623-f9bf-48cd-90ef-710bb182d5c7"
   },
   "outputs": [],
   "source": [
    "from transformers import DistilBertForSequenceClassification\n",
    "\n",
    "# Load DistilBERT with classification head\n",
    "model = DistilBertForSequenceClassification.from_pretrained(\"distilbert-base-uncased\", num_labels=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uYnO9Z8pXQjU"
   },
   "source": [
    "### 3.3 Training setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 49,
     "referenced_widgets": [
      "351e6487bf7949eb8d5d434fd16bdb34",
      "12f6d5a5459742c7832895628c5494a4",
      "6fd0ce39901643f7b95da3886e32f08c",
      "b07ee2cc3a9741ceb872f3b149e6bb93",
      "c55ffcf7fd53415498bfe5c151bddacc",
      "f005bb3841d348889f652638f3509067",
      "2b6de788c08441ccb98d9b5156eef950",
      "a158ade8800348548402d2d695628658",
      "0926b78d50b44a98a3b0b7cfacf15355",
      "d5a7417be7eb4698af193c50435ba4c5",
      "8f34a6c4321a446aa2a189687d169b65"
     ]
    },
    "id": "ncoKXWaiXM_Y",
    "outputId": "c2a214a8-75ad-436f-bb29-523ceaedbc46"
   },
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer\n",
    "import evaluate\n",
    "\n",
    "# Metric\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = logits.argmax(axis=-1)\n",
    "    return accuracy.compute(predictions=predictions, references=labels)\n",
    "\n",
    "# Training arguments\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./results\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    num_train_epochs=1,\n",
    "    weight_decay=0.01,\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=50,\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"accuracy\",\n",
    "    report_to=\"none\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "G9kTvy5XX6uk"
   },
   "source": [
    "### 3.4 Entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 143
    },
    "id": "MPtCWjo_XU_A",
    "outputId": "e10d6bde-347d-432e-a3ba-9a2b21e424cc"
   },
   "outputs": [],
   "source": [
    "# define Trainer\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_dataset[\"train\"],\n",
    "    eval_dataset=tokenized_dataset[\"test\"],\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n",
    "\n",
    "# train\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICCd5C4Gfagw"
   },
   "source": [
    "## Partie 4 : Comparaison des modèles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1djWoSWRfn8e"
   },
   "source": [
    "### 4.1 Évaluation Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k66XFpZKaomH",
    "outputId": "13ae8450-a246-49e3-8810-a2172e88499d"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "y_pred_baseline = baseline_model.predict(X_test)\n",
    "acc_baseline = accuracy_score(y_test, y_pred_baseline)\n",
    "\n",
    "print(\"Baseline TF-IDF + LogReg Accuracy:\", acc_baseline)\n",
    "print(classification_report(y_test, y_pred_baseline, target_names=[\"Negative\", \"Positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "K_mPi4Pzfx_E"
   },
   "source": [
    "### 4.2 Évaluation DistilBERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 200
    },
    "id": "EUb01Rglfl42",
    "outputId": "2305b352-fb46-4e42-9dc6-1720e466ed34"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "results_bert = trainer.evaluate()\n",
    "acc_bert = results_bert[\"eval_accuracy\"]\n",
    "\n",
    "print(\"DistilBERT Accuracy:\", acc_bert)\n",
    "\n",
    "preds = trainer.predict(tokenized_dataset[\"test\"])\n",
    "y_pred_bert = np.argmax(preds.predictions, axis=1)\n",
    "y_true_bert = preds.label_ids\n",
    "\n",
    "print(classification_report(y_true_bert, y_pred_bert, target_names=[\"Negative\", \"Positive\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lT5d4ngRf3G4"
   },
   "source": [
    "### 4.3 Matrice de confusion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 927
    },
    "id": "zbBcVaINf5Au",
    "outputId": "87cc24cf-cd6e-4c48-9c6b-837c951fd4ae"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "def plot_confusion(y_true, y_pred, title):\n",
    "    cm = confusion_matrix(y_true, y_pred)\n",
    "    sns.heatmap(cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
    "                xticklabels=[\"Negative\",\"Positive\"],\n",
    "                yticklabels=[\"Negative\",\"Positive\"])\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Predicted\")\n",
    "    plt.ylabel(\"True\")\n",
    "    plt.show()\n",
    "\n",
    "# Baseline confusion matrix\n",
    "plot_confusion(y_test, y_pred_baseline, \"TF-IDF + LogReg\")\n",
    "\n",
    "# DistilBERT confusion matrix\n",
    "plot_confusion(y_true_bert, y_pred_bert, \"DistilBERT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "arylsgWaf9XY",
    "outputId": "90b477cf-a8be-4109-f1cd-b17be536e89d"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison = pd.DataFrame({\n",
    "    \"Model\": [\"TF-IDF + LogReg\", \"DistilBERT\"],\n",
    "    \"Accuracy\": [acc_baseline, acc_bert]\n",
    "})\n",
    "\n",
    "print(comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtTCwxyFtR4C"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "2dW2-wX4lM1o",
    "D32OVtqcljyN",
    "QwWLYKQ0lR7d",
    "HcakFkjpaBXW",
    "egcCOxq6R2zN",
    "E4n6YyDIR_nP"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
