# üé¨ IMDB Sentiment Analysis

Ce projet impl√©mente un syst√®me de classification de critiques de films (positives / n√©gatives) bas√© sur :
- **Baseline** : TF-IDF + R√©gression Logistique
- **LoRA (PEFT)** : Fine-tuning de DistilBERT

Il inclut aussi :
- üìä Outils d‚Äô√©valuation
- üîç Explication locale avec LIME
- üëÄ Visualisation des poids d‚Äôattention
- üåê API FastAPI pour la pr√©diction

---

## üìë Index des livrables

Dans le dossier "documents/" se trouvent les livrables de ce projet et des questions techniques compl√©mentaires.

## Questions techniques
- [Question 1 : g√©n√©ration de descriptions d'armes RPG](documents/question_01.md)  
- [Question 2 : pipeline de build et tests Unity](documents/question_02.md)  
- [Question 3 (bonus) : outils d'√©diteur p√©dagogiques dans Unity](documents/question_03.md)  

## Projet IMDB ‚Äì Analyse de sentiments
- [Notebook d‚Äôanalyse exploratoire des donn√©es](documents/data_analysis_imdb.ipynb) :
Ce notebook comprend la partie analyse du dataset en Partie 1. Il se poursuit en partie avec l'entrainement d'un mod√®le Baseline (Partie 2), d'un LoRA (Partie 3) et une comparaison tr√®s simpliste de ces deux mod√®les (Partie 4). Le but √©tait de refaire ce projet d'analyse de sentiments dans une version ultra simpliste "straight to the point".
- [Rapport technique ‚Äì IMDB](documents/rapport_technique.md)  



## ‚öôÔ∏è Installation & Setup

### 1. Cr√©er l‚Äôenvironnement (Conda recommand√©)
```bash
conda create -n imdb-sentiment python=3.11
conda activate imdb-sentiment
````

### 2. Installer les d√©pendances

```bash
pip install -e .
```

#### GPU config (optionnel mais recommand√©)
Si vous voulez faire tourner vos mod√®les sur votre GPU et que votre config le permet (cuda >11.8) 
```bash
# Installez PyTorch avec CUDA si vous avez un GPU NVIDIA :
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121
# ou pour CUDA 11.8
pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu118
```


---

## üìÇ Structure du projet

```
IMDB-sentiment/
‚îÇ
‚îú‚îÄ src/                   # Code source
‚îÇ   ‚îú‚îÄ data/          	  # Methods de manipulation des donn√©es
‚îÇ   ‚îú‚îÄ training/          # Scripts d‚Äôentra√Ænement
‚îÇ   ‚îú‚îÄ prediction/        # √âvaluation, explications, visualisations
‚îÇ   ‚îî‚îÄ utils/             # Gestion fichiers, erreurs, logs
‚îÇ
‚îú‚îÄ artifacts/             # Mod√®les sauvegard√©s (baseline & LoRA)
‚îú‚îÄ reports/               # Rapports (LIME, logs)
‚îú‚îÄ results/               # R√©sultats chiffr√©s
‚îú‚îÄ configs/               # Configurations YAML
‚îÇ
‚îú‚îÄ pyproject.toml         # D√©claration des scripts ex√©cutables
‚îî‚îÄ README.md
```

---

## üöÄ Commandes disponibles

Les ex√©cutables sont d√©clar√©s dans `pyproject.toml` et peuvent √™tre lanc√©s directement.

---

### üéì Entra√Ænement baseline (TF-IDF + LogReg)

```bash
train_baseline [--model_id ID]
```

* **Description** : Entra√Æne un mod√®le baseline simple.
* **Param√®tres** :

  * `--model_id` *(str, optionnel)* : identifiant du mod√®le (par d√©faut = g√©n√©r√© automatiquement).

---

### üéì Entra√Ænement LoRA (DistilBERT + PEFT)

```bash
train_lora [--epochs E] [--batch_size N] [--max_length L] [--lr LR] [--model_id ID]
```

* **Description** : Fine-tune DistilBERT avec LoRA.
* **Param√®tres** :

  * `--epochs` *(int)* : nombre d‚Äô√©poques d‚Äôentra√Ænement.
  * `--batch_size` *(int)* : taille des batchs (doit √™tre >0, id√©alement puissance de 2).
  * `--max_length` *(int)* : longueur max des s√©quences tokenis√©es.
  * `--lr` *(float)* : learning rate.
  * `--model_id` *(str, d√©faut: timestamp)* : identifiant unique du mod√®le.

---

### üìä √âvaluation d‚Äôun mod√®le

```bash
evaluate --model_type {baseline,lora} [--model_id ID] [--batch_size N] [--npreds K]
```

* **Description** : √âvalue un mod√®le entra√Æn√© sur IMDB.
* **Param√®tres** :

  * `--model_type` *(str)* : `baseline` ou `lora`.
  * `--model_id` *(str)* : identifiant du mod√®le (par d√©faut = dernier trouv√©).
  * `--batch_size` *(int)* : taille des batchs de pr√©diction.
  * `--npreds` *(int, optionnel)* : limite du nombre d‚Äôexemples test√©s.

---

### üîç Explication locale (LIME)

```bash
explain --text "Your review here" --model_type {baseline,lora} [--model_id ID]
```

* **Description** : G√©n√®re une explication locale (LIME) pour un texte donn√©.
* **Param√®tres** :

  * `--text` *(str)* : critique de film √† expliquer.
  * `--model_type` *(str)* : `baseline` ou `lora`.
  * `--model_id` *(str)* : identifiant du mod√®le (par d√©faut = dernier trouv√©).
* **Sortie** : un fichier HTML dans `reports/`.

---

### üëÄ Visualisation des poids d‚Äôattention

```bash
attention --text "Your review here" [--model_id ID]
```

* **Description** : Visualise les scores d‚Äôattention du mod√®le.
* **Param√®tres** :

  * `--text` *(str)* : critique de film.
  * `--model_id` *(str)* : identifiant du mod√®le (par d√©faut = dernier trouv√©).

---

### üåê API FastAPI

```bash
start_api
```

* **Description** : Lance une API FastAPI pour pr√©dire via HTTP.
* **Endpoints** :

  * `POST /predict`

    * **Body** :

      ```json
      {
        "text": "This movie was amazing!",
        "model_id": "latest"
      }
      ```
    * **Retour** :

      ```json
      {
        "label": "pos",
        "probs": {"neg": 0.12, "pos": 0.88}
      }
      ```

---

## üìå Notes

* Les mod√®les et r√©sultats sont stock√©s avec un **ID unique** (timestamp).
* Utiliser `"latest"` comme `model_id` pour charger automatiquement le dernier mod√®le sauvegard√©.
* Les rapports et logs sont disponibles dans le dossier `reports/`.

---
